FANN_FLO_2.1
num_layers=4
learning_rate=0.900000
connection_rate=0.700000
network_type=0
learning_momentum=0.200000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_max_cand_epochs=150
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535520000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000005960464480000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=13 8 4 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (9, 4, 5.00000000000000000000e-001) (9, 4, 5.00000000000000000000e-001) (10, 4, 5.00000000000000000000e-001) (9, 4, 5.00000000000000000000e-001) (10, 4, 5.00000000000000000000e-001) (9, 4, 5.00000000000000000000e-001) (10, 4, 5.00000000000000000000e-001) (0, 4, 5.00000000000000000000e-001) (6, 4, 5.00000000000000000000e-001) (6, 4, 5.00000000000000000000e-001) (6, 4, 5.00000000000000000000e-001) (0, 4, 5.00000000000000000000e-001) (4, 8, 5.00000000000000000000e-001) (0, 8, 5.00000000000000000000e-001) 
connections (connected_to_neuron, weight)=(12, -8.40438246726989750000e-001) (7, 4.27799969911575320000e-001) (5, 6.32098615169525150000e-002) (4, -7.25322812795639040000e-002) (1, 2.37225666642189030000e-001) (10, 8.60740005970001220000e-001) (9, 1.64141416549682620000e+000) (3, 5.55972874164581300000e-001) (0, -3.57566058635711670000e-001) (12, 2.89517194032669070000e-001) (0, 1.33196735382080080000e+000) (2, 1.16816985607147220000e+000) (5, 1.37662029266357420000e+000) (9, 2.30709835886955260000e-001) (10, 6.62799119949340820000e-001) (8, 8.48462879657745360000e-001) (7, 1.16490089893341060000e+000) (6, 7.57523119449615480000e-001) (12, 6.01803183555603030000e-001) (1, 1.41538405418396000000e+000) (7, 6.16760730743408200000e-001) (11, 5.78796565532684330000e-001) (10, 2.87834286689758300000e-001) (8, 5.98643064498901370000e-001) (2, 5.16627907752990720000e-001) (9, 1.09878695011138920000e+000) (5, 1.22785377502441410000e+000) (0, 6.12682759761810300000e-001) (12, -4.22356985509395600000e-002) (4, 9.05709624290466310000e-001) (2, 1.09880793094635010000e+000) (1, 9.64182734489440920000e-001) (5, 4.46498751640319820000e-001) (9, 1.31458532810211180000e+000) (10, 7.68538773059844970000e-001) (8, 4.39519762992858890000e-001) (7, 6.15624114871025090000e-002) (12, -3.68563461303710940000e+000) (6, 3.33421230316162110000e-001) (4, 3.51053737103939060000e-002) (9, 1.43249344825744630000e+000) (2, 4.48518931865692140000e-001) (3, -3.83558571338653560000e-001) (10, 1.85463237762451170000e+000) (8, 1.61681616306304930000e+000) (7, 1.21820163726806640000e+000) (0, -6.74533128738403320000e-001) (12, -9.54160332679748540000e-001) (3, 1.15011902526021000000e-002) (6, -1.19987264275550840000e-001) (8, -1.54062315821647640000e-001) (11, 2.87804484367370610000e+000) (10, -3.18048857152462010000e-002) (5, -2.78755165636539460000e-002) (1, -2.95004189014434810000e-001) (0, -1.17631636559963230000e-001) (12, -1.18214547634124760000e+000) (5, 3.89233678579330440000e-001) (3, 9.19449031352996830000e-001) (4, 5.60868442058563230000e-001) (9, 5.38040399551391600000e-001) (0, 1.18275201320648190000e+000) (10, 6.58886373043060300000e-001) (1, 8.67210924625396730000e-001) (7, 7.55092322826385500000e-001) (2, 9.32204306125640870000e-001) (20, -9.15451467037200930000e-001) (17, 9.28433060646057130000e-001) (19, 1.59178331494331360000e-001) (13, 3.61924260854721070000e-001) (16, 1.34505271911621090000e+000) (18, 1.16097223758697510000e+000) (20, -1.79499423503875730000e+000) (13, 1.06952321529388430000e+000) (16, -6.06894083321094510000e-002) (18, 2.48215723037719730000e+000) (15, 1.60331770777702330000e-001) (17, 9.02307987213134770000e-001) (20, -1.65512013435363770000e+000) (14, 3.55539590120315550000e-001) (15, -2.18993611633777620000e-002) (17, 7.81885683536529540000e-001) (13, 3.52671384811401370000e-001) (16, 9.07577350735664370000e-002) (24, -2.24536037445068360000e+000) (21, -2.76468414813280110000e-002) (22, 2.03014588356018070000e+000) (23, -3.47942888736724850000e-001) 
